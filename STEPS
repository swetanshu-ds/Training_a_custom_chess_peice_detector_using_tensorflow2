        https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb\
1. Make a folder directly in google drive as TFOD2.x
2. You can choose any name but make sure to remember the name
3. Now make a colab notebook outside the TFOD2. and not in the TFOD2.x folder and mount the google drive
4. Now after mounting copy the TFOD2.x path and type %cd /content/drive/MyDrive/TFOD2.x
5. Write these commands as shown below one by one 
6. %cd /content/drive/MyDrive/TFOD2.x
7. !pip install -U --pre tensorflow=="2.*"
8. !pip install tf_slim
9. !pip install pycocotools
10. 
    import os
    import pathlib


    if "models" in pathlib.Path.cwd().parts:
      while "models" in pathlib.Path.cwd().parts:
        os.chdir('..')
    elif not pathlib.Path('models').exists():
      !git clone --depth 1 https://github.com/tensorflow/models
      
      
11.   using ash command we will do the conversion of protos files to proto python file (.py) 
    %%bash
    cd models/research/
    protoc object_detection/protos/*.proto --python_out=.


12. 

    %cd models/research
    #  the cp copmmand will copy the setup.py file to the roiginal directory that is models research folder so that it can directly be installed 
    !cp /content/drive/MyDrive/TFOD2.x/models/research/object_detection/packages/tf2/setup.py .
    !pip install .

13. 

import numpy as np
import os
import six.moves.urllib as urllib
import sys
import tarfile
import tensorflow as tf
import zipfile

from collections import defaultdict
from io import StringIO
from matplotlib import pyplot as plt
from PIL import Image
from IPython.display import display



14. 
from object_detection.utils import ops as utils_ops
from object_detection.utils import label_map_util
from object_detection.utils import visualization_utils as vis_util
# THis is used to check whether all the object_detection library are working properly or not

15. 

# patch tf1 into `utils.ops`
utils_ops.tf = tf.compat.v1

# Patch the location of gfile
tf.gfile = tf.io.gfile

                    Download Pretrained Model 
                    right now we are content but we want to be in objectDetection so move to oject_detection
                    %cd /content/drive/MyDrive/TFOD2.x/models/research/object_detection/chess_dataset
                    
16. Now transfer or copy the dataset from the chess_dataset folder to the model-> research-> object_detection

17. Before sending the chess_dataset.zip to model-> research-> object_detection ,first make sure you download the data in your 
                                                         local system and then extract it ,then only send the the data



#   generate_tfrecord files is used does annotation of images


18.   Till here our Preparing the dataset for training is done.

19.  Go to the github website 
        https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md

20. Choose any model 
21.  For example we have choosed here this modes 
        http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz
        
22.  Now we have to clone this model into our object_detection
23.  First change the path
24. use this  %cd /content/drive/MyDrive/TFOD2.x/models/research/object_detection
25.  Now use= ===

  !wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz
  
  26. Since it was a tar file ,so we need  to un- tar it ,means unzip it.
  27. For untar - use
  
        !tar -xvf ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz



                FILES SETUP FOR TRAINING
                
 
 
 28.    Create a folder names as training and inside it move the labelmap.pbtxt
 29.   Now in our google drive tod2.x -> model-> research-> object_detection   copy the training folder and  generate_tfrecorc.py file
 30.   
                            Generating tfrecords file from csv format
 
        !python generate_tfrecord.py --csv_input=chess_dataset/train/train.csv --image_dir=chess_dataset/train --output_path=train.record
 
 
        !python generate_tfrecord.py --csv_input=chess_dataset/valid/test.csv --image_dir=chess_dataset/valid --output_path=test.record
 
 31.  Now after running the above two command line train.record and test.record both file will be grnerated that we will need for our upcoming task
 
 32.   Now we will be needing the config file
 33.    For that it will be inside modelsresearch objject detection and then ssd_reset50_v1_FPN and inside it there will  pipeline config file.
 
 34 Now do the following changes in config file
 35. Line 3 = num_class = 6
     line 161 == fine_tune_checkpoint: "PATH_TO_BE_CONFIGURED"  ->  fine_tune_checkpoint:  'ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0'
     
 36. line 172 == label_map_path: "PATH_TO_BE_CONFIGURED" ->     label_map_path: "training/labelmap.pbtxt"
    
 37. line 182 == label_map_path: "PATH_TO_BE_CONFIGURED" ->     label_map_path: "training/labelmap.pbtxt"
 
 38.  line 174 == input_path: "PATH_TO_BE_CONFIGURED"    ->     input_path: "train.record"
 39.  line 186 == input_path: "PATH_TO_BE_CONFIGURED"      ->    input_path: "test.record"
 40.  line 167 ==  fine_tune_checkpoint_type: "classification" ->  fine_tune_checkpoint_type: "detection"
        line 131 = bacth_size = 1 or 8 
 
 Now do control + S to save 
 
 
 41. Now go to the object_detection folder and inside it go to the ssd_resnet_50 folder and the move the pipeline.config to the training folder 
 
                         Till here the files are setup for the training
                         
                         
                         
                         
                         
                         
                        Now lets start the training procedure
                        
                        


42.        A file will be needed names as  - =======      model_main_tf2.py       
/content/drive/MyDrive/TFOD2.x/models/research/object_detection/model_main_tf2.py
43. It is available under the model-> research-> object_detection -> model_main_tf2.py  

44. We have to change multiple thigs in pipeline file which is present two place - ssd_resnet_ and training folder
45. Modify both 
46. 
. Line 3 = num_class = 6
     line 161 == fine_tune_checkpoint: "PATH_TO_BE_CONFIGURED"  ->  fine_tune_checkpoint:  'ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0'
     
  line 172 == label_map_path: "PATH_TO_BE_CONFIGURED" ->     label_map_path: "training/labelmap.pbtxt"
    
  line 182 == label_map_path: "PATH_TO_BE_CONFIGURED" ->     label_map_path: "training/labelmap.pbtxt"
 
   line 174 == input_path: "PATH_TO_BE_CONFIGURED"    ->     input_path: "train.record"
   line 186 == input_path: "PATH_TO_BE_CONFIGURED"      ->    input_path: "test.record"
   line 167 ==  fine_tune_checkpoint_type: "classification" ->  fine_tune_checkpoint_type: "detection"
   line 131 = bacth_size = 1 or 8 
   
47. Now paste this line given below and run
                !python model_main_tf2.py --model_dir=training --pipeline_config_path=training/pipeline.config 

48.     It will take so much time

                                                             RESUME_TRAINING
                                                             
49.     Now after this create a folder  in object_detection names as -------   "resume_train"
50.     COPY LABELMAP.PBTXT AND PIPELINE CONFIG FROM  training folder
51.     Now go to resume_train pipeline_config file and change the training to resume_train as follows
        
        
        
        
        in line 172 and 182 
        label_map_path : "resume_train/labelmap.pbtxt"
        
        
        
        
        
        
52.     !python model_main_tf2.py --model_dir=resume_train --pipeline_config_path=resume_train/pipeline.config 
53.     Now run the above line
54.     Now  when you reach 1000 epoch or steps ,than we have to interrupt the training  
55.     So for interrupting use the run time iterupt 
56.     Then copy paste the same command to resume the training
56.     !python model_main_tf2.py --model_dir=resume_train --pipeline_config_path=resume_train/pipeline.config 
57.     Notice that where we interrupted the session at 1000 ,same resume has started from 1000 
58.           



                             Converting CKPT to Saved Model Format
                             Run the below command
                             
 59.    !python exporter_main_v2.py --input_type image_tensor --pipeline_config_path training/pipeline.config --trained_checkpoint_dir training/ --output_directory exported-models/my_model
 60.     It will create a new folder name exported-models and inside it our saved model will be present as named = my_model.
 61.                                                                                    
 
 
 
 
 
                                        Inferencing using the Custom Trained Model in Colab
 
 
 62.     Now open the  object_detection_tutorial.ipynb  uploaded in the github in this folder     . Run it   till imports
 
 63.   In the mean time ,make a new folder inside object_detection named as -======   test_images_chess   and  upload some chess images
 64.    Now write the following command 
           %cd /content/drive/MyDrive/TFOD2.x/models/research/object_detection
           
65.     Run till Loader and dont run loader code
66.     Run from Custom_Model_Inferencing
67.     

                                codes are
                                
import pathlib

def load_custom_model(model_name):
  model_file = model_name
  model_dir = pathlib.Path(model_file)/"saved_model"

  model = tf.saved_model.load(str(model_dir))

  return model
  
  
  
  
  # List of the strings that is used to add correct label for each box.
PATH_TO_LABELS = '/content/drive/MyDrive/TFOD2.x/models/research/object_detection/training/labelmap.pbtxt'
category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)









# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.
PATH_TO_TEST_IMAGES_DIR = pathlib.Path('test_images_chess')
TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob("*.jpg")))
TEST_IMAGE_PATHS





model_name = 'exported-models/my_model'
detection_model = load_custom_model(model_name)





def run_inference_for_single_image(model, image):
  image = np.asarray(image)
  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.
  input_tensor = tf.convert_to_tensor(image)
  # The model expects a batch of images, so add an axis with `tf.newaxis`.
  input_tensor = input_tensor[tf.newaxis,...]

  # Run inference
  model_fn = model.signatures['serving_default']
  output_dict = model_fn(input_tensor)

  # All outputs are batches tensors.
  # Convert to numpy arrays, and take index [0] to remove the batch dimension.
  # We're only interested in the first num_detections.
  num_detections = int(output_dict.pop('num_detections'))
  output_dict = {key:value[0, :num_detections].numpy() 
                 for key,value in output_dict.items()}
  output_dict['num_detections'] = num_detections

  # detection_classes should be ints.
  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)
   
  # Handle models with masks:
  if 'detection_masks' in output_dict:
    # Reframe the the bbox mask to the image size.
    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(
              output_dict['detection_masks'], output_dict['detection_boxes'],
               image.shape[0], image.shape[1])      
    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,
                                       tf.uint8)
    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()
    
  return output_dict






def show_inference(model, image_path):
  # the array based representation of the image will be used later in order to prepare the
  # result image with boxes and labels on it.
  image_np = np.array(Image.open(image_path))
  # Actual detection.
  output_dict = run_inference_for_single_image(model, image_np)
  # Visualization of the results of a detection.
  vis_util.visualize_boxes_and_labels_on_image_array(
      image_np,
      output_dict['detection_boxes'],
      output_dict['detection_classes'],
      output_dict['detection_scores'],
      category_index,
      instance_masks=output_dict.get('detection_masks_reframed', None),
      use_normalized_coordinates=True,
      line_thickness=8)

  display(Image.fromarray(image_np))
  
  
  
  
  
  
  for image_path in TEST_IMAGE_PATHS:
  show_inference(detection_model, image_path)

 












             Now the  oject_detection in colab is Comple\ted
             
             
             
             
             
             Thankyou
